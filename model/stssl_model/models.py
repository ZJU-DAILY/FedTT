from traffic_model.stssl_model.lib.utils import masked_mae_loss
from traffic_model.stssl_model.aug import aug_topology, aug_traffic
from traffic_model.stssl_model.layers import STEncoder, SpatialHeteroModel, TemporalHeteroModel, MLP
import torch.nn as nn


class STSSL(nn.Module):
    def __init__(self, num_nodes, batch_size, output_size, pre_len, args):
        super(STSSL, self).__init__()
        shm_temp = 0.5
        nmb_prototype = 6
        input_length = 12
        dropout = 0.2

        # spatial temporal encoder
        self.encoder = STEncoder(Kt=args.kt, Ks=args.ks,
                                 blocks=[[output_size, int(args.d_model // output_size), args.d_model],
                                         [args.d_model, int(args.d_model // output_size), args.d_model]],
                                 input_length=input_length, num_nodes=num_nodes, droprate=dropout)

        # traffic flow prediction branch
        self.mlp = MLP(args.d_model, pre_len)
        # temporal heterogenrity modeling branch
        self.thm = TemporalHeteroModel(args.d_model, batch_size, num_nodes, 'cuda:1')
        # spatial heterogenrity modeling branch
        self.shm = SpatialHeteroModel(args.d_model, nmb_prototype, batch_size, shm_temp)
        self.mae = masked_mae_loss(mask_value=None)
        self.args = args
       

    def forward(self, view1, graph):
        repr1 = self.encoder(view1, graph)  # view1: n,l,v,c; graph: v,v

        s_sim_mx = self.fetch_spatial_sim()
        graph2 = aug_topology(s_sim_mx, graph, percent=self.args.percent * 2)

        t_sim_mx = self.fetch_temporal_sim()
        view2 = aug_traffic(t_sim_mx, view1, percent=self.args.percent)

        repr2 = self.encoder(view2, graph2)
        return repr1, repr2

    def fetch_spatial_sim(self):
        """
        Fetch the region similarity matrix generated by region embedding.
        Note this can be called only when spatial_sim is True.
        :return sim_mx: tensor, similarity matrix, (v, v)
        """
        return self.encoder.s_sim_mx.cpu()

    def fetch_temporal_sim(self):
        return self.encoder.t_sim_mx.cpu()

    def predict(self, z1, z2):#input:torch.Size([32, 1, 307, 64]) output:torch.Size([32, 1, 307, 1])
        '''Predicting future traffic flow.
        :param z1, z2 (tensor): shape nvc
        :return: nlvc, l=1, c=2
        '''
        return self.mlp(z1).transpose(1, 3)


    def loss(self, z1, z2, y_true, scaler, loss_weights):
        y_pred, l1 = self.pred_loss(z1, z2, y_true, scaler)
        sep_loss = [l1.item()]
        loss = loss_weights[0] * l1

        l2 = self.temporal_loss(z1, z2)
        sep_loss.append(l2.item() )
        loss += loss_weights[1] * l2/(scaler['max'] - scaler['min'])

        l3 = self.spatial_loss(z1, z2)
        sep_loss.append(l3.item()  )
        loss += loss_weights[2] * l3/(scaler['max'] - scaler['min'])
        return y_pred, loss, sep_loss

    def pred_loss(self, z1, z2, y_true, scaler):
        y_pred = self.predict(z1, z2)
        y_true = y_true

        loss = self.mae(y_pred,y_true)
        return y_pred, loss

    def temporal_loss(self, z1, z2):
        return self.thm(z1, z2)

    def spatial_loss(self, z1, z2):
        return self.shm(z1, z2)
